{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "version1_perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CNN0VqGe7mfT",
        "hfq2cMgZVR7D",
        "vBXbHSZZ7vS7",
        "GR7uQ_kXWRoK",
        "l-Z5jfiijE49",
        "hz23md9WWVht",
        "4FJemkvBWbCa",
        "3beJslDC9ACn"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F72ATMM87iuP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNN0VqGe7mfT"
      },
      "source": [
        "# VERSIÓN 1: ALGORITMO DEL PERCEPTRÓN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U85RaeV3WtjP"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaDuTv3mLjP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "413d82e6-cd73-481a-ad4e-00b4aa321199"
      },
      "source": [
        "# Se cargan las imágenes del dataset MNIST\n",
        "(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls-5_AmrWkeV"
      },
      "source": [
        "# Función que visualiza un ejemplo\n",
        "def visualize(sample):\n",
        "  image = training_images[sample]\n",
        "  fig = plt.figure\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfq2cMgZVR7D"
      },
      "source": [
        "## PREPARACIÓN DE LOS DATOS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0d0iHtWVU5r"
      },
      "source": [
        "# Se cambia el tipo de los datos a float32\n",
        "training_images = training_images.astype(\"float32\")\n",
        "test_images = test_images.astype(\"float32\")\n",
        "\n",
        "# Las imágenes pasan de matriz 28x28 a vector 784x1\n",
        "training_images = training_images.reshape(60000, 784)\n",
        "test_images = test_images.reshape(10000, 784)\n",
        "\n",
        "# Normalización: los datos pasan a tener un valor entre [0, 1]\n",
        "training_images = training_images / 255\n",
        "test_images = test_images / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuAhV9ExTD2C"
      },
      "source": [
        "## CLASE NEURON:\n",
        "\n",
        "Representa una neurona. Hay 10 neuronas en total (una para cada dígito)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB58s6xOXXxM"
      },
      "source": [
        "class Neuron:\n",
        "  SIZE = 28*28+1 # +1 porque se incluye la entrada x0 con el peso w0 (bias)\n",
        "\n",
        "  def __init__(self, number, bias):\n",
        "    self.weights = self.init_weights()\n",
        "    self.number = number\n",
        "    self.x0 = 1\n",
        "    self.weights[0] = bias\n",
        "\n",
        "  # Para inicializar los pesos a 0\n",
        "  def init_weights(self):\n",
        "    return np.zeros(self.SIZE)\n",
        "  \n",
        "  # Se calcula la suma de los pesos\n",
        "  # Devuelve True si es mayor o igual que 0\n",
        "  def predict(self, image_number):\n",
        "    # Se inserta añade un 0 en la primera posición (x0)\n",
        "    image_number = np.insert(image_number,0,self.x0)\n",
        "    sum = np.dot(image_number,self.weights)\n",
        "\n",
        "    if sum >= 0:\n",
        "      return True\n",
        "    else:\n",
        "      return False\n",
        "  \n",
        "  # Actualiza los pesos\n",
        "  def update_weights(self, training_image, update_politic):\n",
        "    training_image = np.insert(training_image,0,self.weights[0])\n",
        "    \n",
        "    # Si la salida es 1 pero debería haber sido un 0\n",
        "    if update_politic:\n",
        "      self.weights = np.subtract(self.weights,training_image)\n",
        "    # Si la salida es 0 pero debería haber sido un 1\n",
        "    else:\n",
        "      self.weights = np.add(self.weights,training_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miAKfCmZzzZt"
      },
      "source": [
        "# Se crea una neurona para cada dígito\n",
        "neurons = []\n",
        "for digit in range(10):\n",
        "  neuron = Neuron(digit, 10)\n",
        "  neurons.append(neuron)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tUhfL1jSsCa"
      },
      "source": [
        "## ENTRENAMIENTO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwP3kUE90zgt"
      },
      "source": [
        "# Para cada neurona se le pasa todo el conjunto de entrenamiento\n",
        "# Para cada conjunto de entrenamiento, se calcula si la salida es 1 o 0\n",
        "# Se actualizan los pesos de acuerdo a si acierta o falla\n",
        "start = time.time()\n",
        "\n",
        "for neuron in neurons:\n",
        "  for x in range(len(training_images)):\n",
        "      activated = neuron.predict(training_images[x])\n",
        "      if activated:\n",
        "        if training_labels[x] != neuron.number:\n",
        "          neuron.update_weights(training_images[x], True)\n",
        "      else:\n",
        "        if training_labels[x] == neuron.number:\n",
        "          neuron.update_weights(training_images[x], False)\n",
        "          \n",
        "end = time.time()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_IBTp3TSuyN"
      },
      "source": [
        "## PORCENTAJE DE ERROR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oenb24y801qX",
        "outputId": "ba6e17c0-8481-446b-8083-0a229f409cac"
      },
      "source": [
        "n_errors = np.zeros(10)\n",
        "\n",
        "for neuron in neurons:\n",
        "  for x in range(len(test_images)):\n",
        "      activated = neuron.predict(test_images[x])\n",
        "      if activated:\n",
        "        if test_labels[x] != neuron.number:\n",
        "          n_errors[neuron.number] += 1\n",
        "\n",
        "total_percentage = 0\n",
        "for neuron in neurons:\n",
        "  percentage = n_errors[neuron.number]/len(test_images)*100\n",
        "  total_percentage += percentage\n",
        "  print(\"Clase \"+str(neuron.number)+\": \"+str(percentage)+\"% de error\")\n",
        "  \n",
        "print(\"\\nPorcentaje de error total: \"+str(total_percentage))\n",
        "print(\"Tiempo transcurrido: \"+str(round(end - start,2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clase 0: 0.19% de error\n",
            "Clase 1: 0.42% de error\n",
            "Clase 2: 0.15% de error\n",
            "Clase 3: 4.12% de error\n",
            "Clase 4: 0.43% de error\n",
            "Clase 5: 0.15% de error\n",
            "Clase 6: 1.5% de error\n",
            "Clase 7: 0.3% de error\n",
            "Clase 8: 2.85% de error\n",
            "Clase 9: 2.21% de error\n",
            "\n",
            "Porcentaje de error total: 12.32\n",
            "Tiempo transcurrido: 15.38\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}